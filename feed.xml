<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://canng.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://canng.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-31T10:16:25+00:00</updated><id>https://canng.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">üì∞ Biodiversity intactness footprint data on Scientific Data</title><link href="https://canng.github.io/blog/2025/Paper_SciData_BIIFP/" rel="alternate" type="text/html" title="üì∞ Biodiversity intactness footprint data on Scientific Data"/><published>2025-10-03T00:00:00+00:00</published><updated>2025-10-03T00:00:00+00:00</updated><id>https://canng.github.io/blog/2025/Paper_SciData_BIIFP</id><content type="html" xml:base="https://canng.github.io/blog/2025/Paper_SciData_BIIFP/"><![CDATA[<hr/> <p><br/></p> <h3 id="abstract">Abstract</h3> <p><strong>Global biodiversity</strong> is rapidly declining, primarily due to <strong>agricultural production</strong> driven by both domestic and transboundary consumption. This study addresses the challenges posed by inconsistent spatiotemporal biodiversity data by developing a time series of <strong>biodiversity loss footprints</strong> based on <strong>Biodiversity Intactness Index (BII)</strong>. Numerous land use, land cover, and auxiliary datasets were integrated to produce a consistent time series of high-resolution harmonized land use (HHLU) maps. These maps were utilized to quantify spatial BII using linear-mixed effect models. Biodiversity intactness loss (BII footprint) was subsequently attributed to specific crops and livestock commodities. This study provides comprehensive global datasets, including HHLU and BII maps, and synthesized BII footprints across <strong>14 biomes, 193 countries and territories, 154 crop items, and 9 livestock</strong> categories from 2000 to 2020. These datasets facilitate spatiotemporal analyses to identify trends and patterns in global biodiversity integrity and biodiversity footprints, thereby elucidating the ecological trade-offs embedded in international trade. These insights can encourage appropriate interventions to transform consumption patterns and supply chains toward the effective conservation of global biodiversity.</p> <p><br/></p> <blockquote> <p style="font-size:15px"> <b>Nguyen, C. T.*</b>, Vaƒçk√°≈ôov√°, D. &amp; Weinzettel, J., 2025. <b>Consistent global dataset on biodiversity intactness footprint of agricultural production from 2000 to 2020</b>. Scientific Data, 12, 1613 <a href="https://doi.org/10.1038/s41597-025-05901-0">DOI: 10.1038/s41597-025-05901-0</a><a href="https://canng.github.io/assets/pdf/2025_scidata_BIIFP_Loss.pdf"> <i class="fa-solid fa-file-pdf"></i></a></p> </blockquote> <p><br/></p> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/BIIFP_01-480.webp 480w,/assets/img/pubpic/2025/BIIFP_01-800.webp 800w,/assets/img/pubpic/2025/BIIFP_01-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/BIIFP_01.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Overview of the methodological framework used to generate biodiversity intactness maps and biodiversity loss footprints associated with agricultural production. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/BIIFP_02-480.webp 480w,/assets/img/pubpic/2025/BIIFP_02-800.webp 800w,/assets/img/pubpic/2025/BIIFP_02-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/BIIFP_02.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Harmonized land use map in 2020 and fragmented zoom-in examples in (A) Northeast America, (B) Amazon, (C) Mekong Delta, (D) Eastern Australia, (E) Northeast China, (F) Nile Delta in Egypt, (G) Southern Africa, and (H) Western Europe, depict dominant land use categories globally. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/BIIFP_03-480.webp 480w,/assets/img/pubpic/2025/BIIFP_03-800.webp 800w,/assets/img/pubpic/2025/BIIFP_03-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/BIIFP_03.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Biodiversity intactness index (BII) in 2020 and examples in (A) Northeast America, (B) Amazon, (C) Mekong Delta, (D) Eastern Australia, (E) Northeast China, (F) Nile Delta in Egypt, (G) Southern Africa, and (H) Western Europe. Green represents intact ecosystems and red indicates ecosystems with high human intervention. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/BIIFP_04-480.webp 480w,/assets/img/pubpic/2025/BIIFP_04-800.webp 800w,/assets/img/pubpic/2025/BIIFP_04-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/BIIFP_04.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Summary of BII loss footprints: (A) overall trend of total BII loss footprint on crops and livestock from 2000 to 2020, and comparisons between average footprint and overall trend on (B) biomes, (C) countries/territories, and (D) commodities. The footprint from the livestock sector has gradually declined, whereas the footprint associated with crop production has increased persistently over time. Increases in biodiversity footprints were observed across all biomes, with particularly notable growth in tropical and subtropical moist broadleaf forests, temperate broadleaf and mixed forests, and tropical and subtropical grasslands, savannas, and shrublands. At the country level, footprints increased in nearly all countries, except for Australia and Mongolia, where substantial declines were observed. Among commodities, the most significant increases in footprints were associated with maize, wheat, and meat cattle, while a notable decrease was seen for meat sheep. </div> <p><br/></p>]]></content><author><name></name></author><category term="work"/><category term="publication"/><summary type="html"><![CDATA[Consistent global dataset on biodiversity intactness footprint of agricultural production from 2000 to 2020]]></summary></entry><entry><title type="html">üì¢ Editing a Special Issue on Designing Resilient Cities (Sustainability, MDPI)</title><link href="https://canng.github.io/blog/2025/SI-Sustainability-copy/" rel="alternate" type="text/html" title="üì¢ Editing a Special Issue on Designing Resilient Cities (Sustainability, MDPI)"/><published>2025-07-01T00:00:00+00:00</published><updated>2025-07-01T00:00:00+00:00</updated><id>https://canng.github.io/blog/2025/SI-Sustainability%20copy</id><content type="html" xml:base="https://canng.github.io/blog/2025/SI-Sustainability-copy/"><![CDATA[<hr/> <p><br/></p> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_pics/SI_sustainability_01-480.webp 480w,/assets/img/post_pics/SI_sustainability_01-800.webp 800w,/assets/img/post_pics/SI_sustainability_01-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post_pics/SI_sustainability_01.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>I am currently editing a Special Issue for Sustainability on <b>‚ÄúDesigning Resilient Cities: Landscape-Based Architecture and Green Space Strategies for Urban Sustainability‚Äù</b>, together with: <br/></p> <li><a href="https://scholar.google.com/citations?user=cNYcVQ0AAAAJ&amp;hl=en">Dr. Nigel K. Downes </a> (Can Tho University, Vietnam)</li> <li><a href="https://www.geo.lmu.de/geographie/de/personen/kontaktseite/olabisi-obaitor-4e3afe23.html">Dr. Olabisi S. Obaitor</a> (LMU Munich, Germany)</li> <p><br/></p> <p>This SI explores how landscape architecture, green space planning, and urban nature can contribute to climate-responsive, sustainable, and equitable urban development, particularly across the Global South.</p> <p>We welcome contributions on green-blue infrastructure, nature-based solutions, urban informatics, and interdisciplinary approaches to advance urban climate resilience and social equity.</p> <p>‚ÑπÔ∏è You can find additional details on the following website:<br/> <a href="https://www.mdpi.com/journal/sustainability/special_issues/5F78LD3752">https://www.mdpi.com/journal/sustainability/special_issues/5F78LD3752</a></p> <p>üìÖ Deadline for submissions: <b>30 June 2026</b></p> <p>‚ùìIf you‚Äôre working on projects or research aligned with these themes, consider submitting your work.</p> <p>üì© Feel free to reach out if you wish to discuss ideas before submission.</p> <p><br/></p> <div class="col-sm text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post_pics/SI_sustainability-480.webp 480w,/assets/img/post_pics/SI_sustainability-800.webp 800w,/assets/img/post_pics/SI_sustainability-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post_pics/SI_sustainability.jpg" width="90%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div>]]></content><author><name></name></author><category term="work"/><category term="special-issue"/><summary type="html"><![CDATA[Designing Resilient Cities ‚Äì Landscape-Based Architecture and Green Space Strategies for Urban Sustainability]]></summary></entry><entry><title type="html">üì∞ Deep learning for Fruit tree Classification on RSASE</title><link href="https://canng.github.io/blog/2025/Paper-RSASE-CNN-Fruit/" rel="alternate" type="text/html" title="üì∞ Deep learning for Fruit tree Classification on RSASE"/><published>2025-06-17T00:00:00+00:00</published><updated>2025-06-17T00:00:00+00:00</updated><id>https://canng.github.io/blog/2025/Paper-RSASE-CNN-Fruit</id><content type="html" xml:base="https://canng.github.io/blog/2025/Paper-RSASE-CNN-Fruit/"><![CDATA[<hr/> <p><br/></p> <h3 id="abstract">Abstract</h3> <p>Mapping fruit tree species is an essential task in agricultural planning and management. However, the classification of <strong>tropical fruit tree species</strong> faces many technical challenges because of their identical leaf characteristics, especially in developing countries with limited accessibility to data and advanced technologies. This study attempts to evaluate the effectiveness of currently available satellite images (<strong>Sentinel-2</strong> and <strong>Planet</strong>) and <strong>Gray-level co-occurrence matrix</strong> (GLCM) textural features in discriminating tropical fruit trees using a <strong>conventional neural network</strong> (CNN) compared to other machine learning algorithms. Spectral bands and textural features from Sentinel-2 and Planet images were extracted to input into the CNN model, as well as other five commonly used machine learning models, including K-Nearest Neighbor (KNN), Gradient Boosting Machine (GBM), Naive Bayes (NB), Random Forest (RF), and Support Vector Machine (SVM). The classification results were evaluated based on performance metrics of accuracy, F1-score, and spatial agreement of classified maps. The contribution of each variable in the classification was identified using permutation feature importance. The research findings revealed that the CNN model outperformed the other machine learning models in detecting five major fruit trees (i.e., <strong>coconut, coconut intercropping, durian, pomelo, and rambutan</strong>). The most important contributions to mapping performance were constituted by spectral bands from Sentinel-2 (e.g., shortwave infrared-SWIR, Blue, and Vegetation Red-Edge bands), while Planet image provides vital textural information such as Entropy (ENT), Angular Second Moment (ASM), sum average (SA), and homogeneity (HOM). The research provides valuable insights into classifying tropical fruit trees using entirely free data sources, avoiding the need for costly and complex alternatives. It also presents significant potential for applications in other tropical regions, contributing to sustainable agricultural management.</p> <p><br/></p> <blockquote> <p style="font-size:15px"> <b>Nguyen, C. T.*</b>, Diem, K. P.*, Nghia, D. H., Diem, N. K., Diep, N. T. H., Phan, T. N., Minh, V. Q., Quang, N. H., 2025. <b>Leveraging Convolutional Neural Networks and Textural Features for Tropical Fruit Tree Species Classification</b>. Remote Sensing Applications: Society and Environment. 39, August 2025, 101633 <a href="https://doi.org/10.1016/j.rsase.2025.101633">DOI: 10.1016/j.rsase.2025.101633</a><a href="https://canng.github.io/assets/pdf/2025_RSASE_CNN_TropiTrees.pdf"> <i class="fa-solid fa-file-pdf"></i></a></p> </blockquote> <p><br/></p> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/CNN_Fruit_01-480.webp 480w,/assets/img/pubpic/2025/CNN_Fruit_01-800.webp 800w,/assets/img/pubpic/2025/CNN_Fruit_01-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/CNN_Fruit_01.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Chau Thanh district in Southern Vietnam and locations of ground truth points collected during field survey campaigns. The background is Sentinel-2 image (True color composite). </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/CNN_Fruit_02-480.webp 480w,/assets/img/pubpic/2025/CNN_Fruit_02-800.webp 800w,/assets/img/pubpic/2025/CNN_Fruit_02-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/CNN_Fruit_02.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Field photos of five major fruit tree species demonstrate potential differences in distribution and canopy structure. Source: Authors own field photos. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/CNN_Fruit_03-480.webp 480w,/assets/img/pubpic/2025/CNN_Fruit_03-800.webp 800w,/assets/img/pubpic/2025/CNN_Fruit_03-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/CNN_Fruit_03.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> The proposed concept of CNN model architecture. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/CNN_Fruit_04-480.webp 480w,/assets/img/pubpic/2025/CNN_Fruit_04-800.webp 800w,/assets/img/pubpic/2025/CNN_Fruit_04-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/CNN_Fruit_04.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Heatmap illustrates overlapping rates between different pairs of fruit trees over spectral bands and textural indices. Prefix P. indicates Planet-derived information. Dendrograms group fruit tree combination and indices into identical clusters. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/CNN_Fruit_05-480.webp 480w,/assets/img/pubpic/2025/CNN_Fruit_05-800.webp 800w,/assets/img/pubpic/2025/CNN_Fruit_05-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/CNN_Fruit_05.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Fruit tree maps obtained from different machine learning and CNN models based on spectral and textural indices from Sentinel-2 and Planet images (left panel) and spatial agreement between classified maps and reference layer (right panel). True = Matched, False = Unmatched. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/CNN_Fruit_06-480.webp 480w,/assets/img/pubpic/2025/CNN_Fruit_06-800.webp 800w,/assets/img/pubpic/2025/CNN_Fruit_06-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/CNN_Fruit_06.jpg" width="80%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Classified fruit tree map obtained from CNN model using spectral and textural indices from Sentinel-2 and Planet images. </div> <p><br/></p>]]></content><author><name></name></author><category term="work"/><category term="publication"/><summary type="html"><![CDATA[Leveraging Convolutional Neural Networks and Textural Features for Tropical Fruit Tree Species Classification]]></summary></entry><entry><title type="html">üì∞ Simulate Land use Changes under Scenarios on LAND</title><link href="https://canng.github.io/blog/2025/Paper-LAND-landuse-sim/" rel="alternate" type="text/html" title="üì∞ Simulate Land use Changes under Scenarios on LAND"/><published>2025-05-14T00:00:00+00:00</published><updated>2025-05-14T00:00:00+00:00</updated><id>https://canng.github.io/blog/2025/Paper-LAND-landuse-sim</id><content type="html" xml:base="https://canng.github.io/blog/2025/Paper-LAND-landuse-sim/"><![CDATA[<hr/> <p><br/></p> <h3 id="abstract">Abstract</h3> <p>Land use and land cover (LULC) in coastal areas is critical in shaping the ecological systems, regional economy, and livelihood of indigenous communities. This study analyzes LULC changes (LULCC) in Soc Trang Province, <strong>Vietnam Mekong Delta</strong>, from 2010 to 2020 and simulates future LULC for <strong>2030</strong> under four scenarios: <strong>natural growth (business as usual, BAU), climate change challenges, profit optimization, and adaptation strategies</strong>. Satellite-based LULC maps and geospatial datasets were integrated into a LULC simulation model based on a Markov Chain and Cellular Automata to predict LULC in 2030 under disparate scenarios. Simultaneously, this study also estimates economic values and ecosystem service values as proxies to evaluate benefits and trade-offs between the scenarios. The research findings reveal that the critical LULCC observed during 2010‚Äì2020 are transitions from triple rice crops to double rice crops, rice‚Äìshrimp to brackish aquaculture, and expansion of perennial plantations. These transitional trends will persist at a modest rate under the BAU scenario in 2030. The climate change challenge scenario will intervene up to 24.2% of the total area, with double rice crops reaching the most extensive area compared to other scenarios, about 106,047 ha. The profit optimization scenario will affect 16.03% of the total area, focusing on aquaculture expansion to the maximum shared proportion of 34% (approximately 57,000 ha). Adaptive solutions will emphasize reducing triple rice crops while expanding double rice crops and reviving rice‚Äìshrimp to different extents depending on development pathways. Economic evaluations show a growth trend across scenarios, with maximum returns under profit optimization. Yet, <strong>ecosystem service</strong> values notably highlight <strong>ecological trade-offs</strong>, raising concerns about balancing economic benefits and ecological trade-offs in land use planning. The research findings recommend a comprehensive and multitarget approach to land use planning that integrates ecosystem services into initial assessments to balance benefits and trade-offs in coastal areas commonly affected by LULCC. By adopting well-informed and strategic land use plans that minimize ecological and social impacts, local sustainability and resilience to climate change can be significantly enhanced.</p> <p><br/></p> <blockquote> <p style="font-size:15px"> Diep, N. T. H., Nguyen, T. N., Diem, P. K., &amp; <b>Nguyen, C. T.</b>, 2025. <b>Benefits and Trade-Offs from Land Use and Land Cover Changes Under Different Scenarios in the Coastal Delta of Vietnam</b>. Land. 14 (5, SI: Harnessing the Power of Land Mapping Data for Effective Land Policy Development), 1063 <a href="https://doi.org/10.3390/land14051063">DOI: 10.3390/land14051063</a><a href="https://canng.github.io/assets/pdf/2025_land_LUCC_benefits_tradeoffs.pdf"> <i class="fa-solid fa-file-pdf"></i></a></p> </blockquote> <p><br/></p> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/landuse_sim_01-480.webp 480w,/assets/img/pubpic/2025/landuse_sim_01-800.webp 800w,/assets/img/pubpic/2025/landuse_sim_01-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/landuse_sim_01.jpg" width="90%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Study area map shows location of Soc Trang Province on the southeastern coast of the Vietnam Mekong Delta and current LULC map in 2020 with dike systems and saline intrusion boundary of 4‚Ä∞. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/landuse_sim_02-480.webp 480w,/assets/img/pubpic/2025/landuse_sim_02-800.webp 800w,/assets/img/pubpic/2025/landuse_sim_02-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/landuse_sim_02.jpg" width="90%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Methodological framework visualizes primary data sources and their roles in historical LULC mapping, future LULC simulation, and assessments. </div> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pubpic/2025/landuse_sim_03-480.webp 480w,/assets/img/pubpic/2025/landuse_sim_03-800.webp 800w,/assets/img/pubpic/2025/landuse_sim_03-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pubpic/2025/landuse_sim_03.jpg" width="90%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> LULCC probability maps highlight susceptible areas to LULCC in 2030 scenarios and combined all scenarios compared to the LULC status in 2020. Map values range from 0 to 1, meaning low to high change probability. </div> <p><br/></p>]]></content><author><name></name></author><category term="work"/><category term="publication"/><summary type="html"><![CDATA[Benefits and Trade-Offs from Land Use and Land Cover Changes Under Different Scenarios in the Coastal Delta of Vietnam]]></summary></entry><entry><title type="html">Set-up Windows 10 machine for Deep Learning</title><link href="https://canng.github.io/blog/2024/Install_tensorflow/" rel="alternate" type="text/html" title="Set-up Windows 10 machine for Deep Learning"/><published>2024-06-12T00:00:00+00:00</published><updated>2024-06-12T00:00:00+00:00</updated><id>https://canng.github.io/blog/2024/Install_tensorflow</id><content type="html" xml:base="https://canng.github.io/blog/2024/Install_tensorflow/"><![CDATA[<p><img src="/assets/img/post_pics/2024-03-10-tensorflow_windows.jpg" alt="Download NVIDIA graphic driver"/></p> <h2 id="install-tensorflow-gpu-on-windows-10-nvidia-graphic-card">Install TensorFlow GPU on Windows 10 (NVIDIA graphic card)</h2> <blockquote> <p>My PC specs: <br/> MSI GF 63 8RD <br/> Intel Core i5 8300H CPU @2.30GHz (4 Cores, 8 Threads) <br/> RAM 24 GB (upgraded) <br/> Graphics: NVIDIA GeForce GTX 1050 Ti with Max-Q and Intel(R) UHD Graphics 630 <br/> Windows 10 version 21H2</p> </blockquote> <p><br/></p> <blockquote> <p>Before going further, make sure that your NVIDIA Graphic card is supported CUDA and Machine learning/Deep learning capability with <strong>compute capability of higher equal 3.0</strong> <a href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a></p> </blockquote> <hr/> <p><br/></p> <ol> <li> <p>Install Visual Studio Community 2015-2019</p> <p>TensorFlow in Native Windows requires Microsoft Visual C++ Redistributable for <a href="https://download.visualstudio.microsoft.com/download/pr/4100b84d-1b4d-487d-9f89-1354a7138c8f/5B0CBB977F2F5253B1EBE5C9D30EDBDA35DBD68FB70DE7AF5FAAC6423DB575B5/VC_redist.x64.exe">Visual Studio 2015, 2017, and 2019</a></p> <blockquote> <p>Do not install the lastest version, e.g., 2022</p> </blockquote> </li> <li> <p>Install NVIDIA graphics drivers</p> <p>If your graphic card is suitable for ML/DL with a suitable compute capability, you can download and install the latest version of the graphic card driver by selecting your corresponding card‚Äôs specs. Then, you can install the driver by applying default options.</p> <p><img src="/assets/img/post_pics/2024-03-10-image_01.jpg" alt="Download NVIDIA graphic driver"/></p> </li> <li> <p>Install CUDA resources</p> <ul> <li>Download and install <a href="https://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Windows&amp;target_arch=x86_64&amp;target_version=10&amp;target_type=exe_local">CUDA Toolkit 11.8</a></li> </ul> <p><img src="/assets/img/post_pics/2024-03-10-image_02.jpg" alt="Cuda Toolkit 11.8"/></p> <ul> <li>Download <a href="https://developer.nvidia.com/rdp/cudnn-archive">cuDNN SDK 8.6.0 (for CUDA 11.x for Windows)</a>. You then need to extract the cuDNN files, copy and paste all files and folders into the CUDA install location. E.g., <em>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8</em></li> </ul> <p>Open the <strong>Environmental Variables</strong> and add two new paths:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\bin   
 C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\libnvvp   
</code></pre></div> </div> </li> <li> <p>Install Anaconda 3</p> <ul> <li>Download and install <a href="https://www.anaconda.com/download#downloads">Anaconda 3</a></li> </ul> <p>Then, open <strong>Environment variable</strong> and add three more paths (under PATH)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> C:\Users\yourusername\anaconda3   
 C:\Users\yourusername\anaconda3\Library\bin   
 C:\Users\yourusername\anaconda3\Scripts   
</code></pre></div> </div> <ul> <li>Create a new virtual environment with python=3.10</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> conda create --name cnn python=3.10   
 conda activate cnn   
</code></pre></div> </div> </li> <li> <p>Install TensorFlow 2.10</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> pip install --upgrade pip   
 pip install "tensorflow&lt;2.11"   
</code></pre></div> </div> </li> <li> <p>Verify installation</p> <p>To check whether TensorFlow is installed correctly with GPU support, enter the following codes in Anaconda prompt</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
</code></pre></div> </div> <p>If it returns something like the following line, you have successfully installed TensorFlow with GPU support.</p> <blockquote> <p>[PhysicalDevice(name=‚Äô/physical_device:GPU:0‚Äô, device_type=‚ÄôGPU‚Äô)]</p> </blockquote> <p>Or, you can even test it inside virtual environment</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> import tensorflow as tf  
 print(tf.__version__)  
 print(tf.config.list_physical_devices())  
 print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))  
</code></pre></div> </div> <p>It returns the following lines if you have your GPU in use of TensorFlow</p> <blockquote> <p>2.10.1</p> <p>[PhysicalDevice(name=‚Äô/physical_device:CPU:0‚Äô, device_type=‚ÄôCPU‚Äô), PhysicalDevice(name=‚Äô/physical_device:GPU:0‚Äô, device_type=‚ÄôGPU‚Äô)]</p> <p>Num GPUs Available: 1</p> </blockquote> </li> <li> <p>Fix kernel dies when running tensorflow code (additional)</p> <p>If you face an error of <em>kernel dies</em> when you run the TensorFlow codes <strong>The kernel appears to have died</strong></p> <ul> <li>Go to ‚ÄúC:\Program Files\Microsoft Office\root\Office16\ODBC Drivers\Salesforce\lib‚Äù</li> <li>Locate the file, <strong>‚Äúzlibwapi.dll‚Äù</strong></li> <li>Copy and paste it into the CUDA toolkit folder at ‚ÄúC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin‚Äù</li> </ul> </li> </ol> <h4 id="sources">Sources</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;https://www.lavivienpost.com/install-tensorflow-gpu-on-windows-complete-guide/&gt;  
&lt;https://github.com/microsoft/vscode-jupyter/issues/9157&gt;   
&lt;https://www.tensorflow.org/install/pip#windows-wsl2_1&gt;    
</code></pre></div></div>]]></content><author><name></name></author><category term="post"/><category term="python,"/><category term="tips"/><summary type="html"><![CDATA[]]></summary></entry></feed>